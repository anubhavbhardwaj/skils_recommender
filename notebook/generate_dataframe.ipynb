{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1918614d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from datetime import date "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae0f0f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSkills(x , unique_skills):\n",
    "    l = list()\n",
    "    for i in str(x).split():\n",
    "        if i in unique_skills: \n",
    "            l.append(i)\n",
    "    if len(l)== 0:\n",
    "        return None\n",
    "    l = list(set(l))\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50e0b693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging both basic qualifications and preferred qualifications\n",
    "def merge(x) : \n",
    "    if x['BASIC QUALIFICATIONS'] == None and x['PREFERRED QUALIFICATIONS'] != None : \n",
    "        return x['PREFERRED QUALIFICATIONS']\n",
    "    elif x['BASIC QUALIFICATIONS'] != None and x['PREFERRED QUALIFICATIONS'] == None : \n",
    "        return x['BASIC QUALIFICATIONS']\n",
    "    elif x['BASIC QUALIFICATIONS'] == None and x['PREFERRED QUALIFICATIONS'] == None :\n",
    "        return None \n",
    "    return x['BASIC QUALIFICATIONS'] + x['PREFERRED QUALIFICATIONS']\n",
    "\n",
    "\n",
    "def load_data() : \n",
    "    amazon = pd.read_csv('../data/raw/amazon_jobs_dataset.csv')\n",
    "    skills  = pd.read_csv('../data/raw/skills.csv' , dtype = str) \n",
    "\n",
    "    skills = skills.unstack(level = 0 ).dropna().reset_index()[0]\n",
    "    l = list()\n",
    "    for i in skills.values  : \n",
    "        for j in i.split(';') :\n",
    "            l.append(j) \n",
    "    unique_skills = list(set(l))\n",
    "    \n",
    "\n",
    "    amazon['BASIC QUALIFICATIONS'] = amazon['BASIC QUALIFICATIONS'].apply(lambda x : getSkills(x , unique_skills) )\n",
    "    amazon['PREFERRED QUALIFICATIONS'] = amazon['PREFERRED QUALIFICATIONS'].apply(lambda x : getSkills(x , unique_skills))\n",
    "    amazon['Posting_date'] = pd.to_datetime(amazon['Posting_date'])\n",
    "    amazon.drop('Unnamed: 0' , axis = 1 , inplace = True)\n",
    "    \n",
    "    print (amazon.shape)\n",
    "\n",
    "    amazon['QUALIFICATIONS'] = amazon.apply(merge , axis = 1)\n",
    "    amazon.drop(['BASIC QUALIFICATIONS' , 'PREFERRED QUALIFICATIONS'] ,axis = 1 , inplace = True )\n",
    "    amazon.dropna(inplace= True)\n",
    "    \n",
    "    \n",
    "\n",
    "    amazon = amazon.loc[ : , ['Title' , 'QUALIFICATIONS' , 'Posting_date']]\n",
    "    cnt =0 \n",
    "    for i in amazon.iterrows():\n",
    "        for j in i[1]['QUALIFICATIONS']:\n",
    "            amazon.loc[cnt,j] = 1\n",
    "        cnt+=1\n",
    "    \n",
    "    amazon.fillna(0 , inplace = True)\n",
    "    amazon = amazon[amazon.Title != 0]\n",
    "    amazon.drop('QUALIFICATIONS' , axis =1 , inplace = True )\n",
    "\n",
    "    hashmap= {} \n",
    "    \n",
    "    for i , j in amazon.groupby('Title') : \n",
    "        hashmap[i] = j.sort_values(by = 'Posting_date' , ascending= False).iloc[0,2:]\n",
    "\n",
    "    #     Dataframe for skills corresponding to each role \n",
    "    finalDF = pd.DataFrame(hashmap).T\n",
    "\n",
    "    return finalDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7a4ce6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_df = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd20a5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon = pd.read_csv('../data/raw/amazon_jobs_dataset.csv')\n",
    "skills  = pd.read_csv('../data/raw/skills.csv' , dtype = str) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec7f744c",
   "metadata": {},
   "outputs": [],
   "source": [
    "skills = skills.unstack(level = 0 ).dropna().reset_index()[0]\n",
    "l = list()\n",
    "for i in skills.values  : \n",
    "    for j in i.split(';') :\n",
    "        l.append(j) \n",
    "unique_skills = list(set(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3337dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon['BASIC QUALIFICATIONS'] = amazon['BASIC QUALIFICATIONS'].apply(lambda x : getSkills(x , unique_skills) )\n",
    "amazon['PREFERRED QUALIFICATIONS'] = amazon['PREFERRED QUALIFICATIONS'].apply(lambda x : getSkills(x , unique_skills))\n",
    "amazon['Posting_date'] = pd.to_datetime(amazon['Posting_date'])\n",
    "amazon.drop('Unnamed: 0' , axis = 1 , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31c897f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon['QUALIFICATIONS'] = amazon.apply(merge , axis = 1)\n",
    "amazon.drop(['BASIC QUALIFICATIONS' , 'PREFERRED QUALIFICATIONS'] ,axis = 1 , inplace = True )\n",
    "amazon.dropna(inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf065a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon = amazon.loc[ : , ['Title' , 'QUALIFICATIONS' , 'Posting_date']]\n",
    "cnt =0 \n",
    "for i in amazon.iterrows():\n",
    "    for j in i[1]['QUALIFICATIONS']:\n",
    "        amazon.loc[cnt,j] = 1\n",
    "    cnt+=1\n",
    "\n",
    "amazon.fillna(0 , inplace = True)\n",
    "amazon = amazon[amazon.Title != 0]\n",
    "amazon.drop('QUALIFICATIONS' , axis =1 , inplace = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6131340e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashmap= {} \n",
    "    \n",
    "for i , j in amazon.groupby('Title') : \n",
    "    hashmap[i] = j.sort_values(by = 'Posting_date' , ascending= False).iloc[0,2:]\n",
    "\n",
    "#     Dataframe for skills corresponding to each role \n",
    "finalDF = pd.DataFrame(hashmap).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "250393e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "finalDF.to_csv('../data/intermediate/final_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1c15e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
